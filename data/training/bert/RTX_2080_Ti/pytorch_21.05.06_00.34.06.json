{
    "backend": "native",
    "batch_size": 32,
    "batch_size_per_device": 32,
    "channels_first": true,
    "cudnn_benchmark": true,
    "device": "GeForce RTX 2080 Ti",
    "framework": "pytorch",
    "framework_full": "PyTorch-1.6.0",
    "gflop_per_joule": 8.917780675008064,
    "gflop_per_joule_CPU": 66.24521915337662,
    "gflop_per_joule_GPU": 10.663164959779452,
    "gflop_per_joule_device": 10.663164959779452,
    "gflop_per_second": 3038.711132316264,
    "gpus": [
        0
    ],
    "mode": "training",
    "nb_epoch": 10,
    "nb_gpus": 1,
    "path_out": "./logs/training/bert/RTX_2080_Ti",
    "platform": {
        "cpu": {
            "brand": "Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz",
            "cache": {
                "1": 32768,
                "2": 262144,
                "3": 31457280
            },
            "clock": 1701.5395625000003,
            "clock_max": 2900.0,
            "clock_min": 1200.0,
            "logical_cores": 48,
            "physical_cores": 12
        },
        "gpus": [
            {
                "brand": "GeForce RTX 2080 Ti",
                "clock": 1635000,
                "compute_capability": 7.5,
                "cores": null,
                "memory": 11554717696,
                "memory_clock": 7000000,
                "multiprocessors": 68,
                "warp_size": 32
            }
        ],
        "hdds": {
            "/dev/nvme0n1": {
                "model": "INTEL SSDPEDMW800G4                     ",
                "size": 1562824368
            },
            "/dev/sda": {
                "model": "Samsung SSD 850 ",
                "size": 1000215216
            },
            "/dev/sdb": {
                "model": "Samsung SSD 850 ",
                "size": 1000215216
            }
        },
        "host": "kiev2.m.gsic.titech.ac.jp",
        "os": "Linux-3.10.0-1062.18.1.el7.x86_64-x86_64-with-centos-7.8.2003-Core",
        "ram": {
            "total": 270178746368
        },
        "swap": 0
    },
    "power": {
        "avg_watt_CPU": 45.87064804300487,
        "avg_watt_GPU": 284.9727209302325,
        "avg_watt_RAM": 9.904093097925989,
        "avg_watt_total": 340.7474620711634,
        "joules_CPU": 431.796929,
        "joules_GPU": 2682.5508467001746,
        "joules_RAM": 93.230795,
        "joules_total": 3207.5785707001746,
        "sampling_ms": 100
    },
    "preheat": false,
    "problem": {
        "cnt_batches_per_epoch": 4,
        "cnt_samples": 128,
        "gflop_estimated": 28604.482191360003,
        "len_sequence": 128,
        "name": "bert",
        "precision": "FP32",
        "size": [
            128,
            128
        ]
    },
    "profile_pytorch": false,
    "samples_per_joule": 0.39905491690593003,
    "samples_per_joule_CPU": 2.964356423201889,
    "samples_per_joule_GPU": 0.47715777748426924,
    "samples_per_joule_device": 0.47715777748426924,
    "samples_per_second": 135.97695016271464,
    "tensor_layout": "native",
    "time_batch": 0.2353340030182153,
    "time_epoch": 0.9413360120728612,
    "time_sample": 0.007354187594319228,
    "time_total": 9.413360120728612
}